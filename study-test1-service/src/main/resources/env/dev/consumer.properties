#zk访问地址
zookeeper.connect=192.168.134.129:2181
#group.id,消费者组--->多应用消费同一条消息使用组区分
group.id=${cafka.group.id}
# 消费者的ID，若是没有设置的话，会自增
consumer.id=1
#zookeeper的心跳超时时间，超过过这个时间就认为是无效的消费者
zookeeper.session.timeout.ms=6000
#zookeeper的等待连接时间
zookeeper.connection.timeout.ms=15000
#zookeeper的follower同leader的同步时间
zookeeper.sync.time.ms=2000
#当zookeeper中没有初始的offset时，或者超出offset上限时的处理方式 。
#smallest ：重置为最小值 
#largest:重置为最大值 
#anything else：抛出异常给consumer
auto.offset.reset=largest
#socket的超时时间，实际的超时时间为max.fetch.wait + socket.timeout.ms.
socket.timeout.ms=30000
#socket的接收缓存空间大小64 * 1024
socket.receive.buffer.bytes=65536
#从每个分区fetch的消息大小限制1024 * 1024
fetch.message.max.bytes=1048576
#true时，Consumer会在消费消息后将offset同步到zookeeper，这样当Consumer失败后，新的consumer就能从zookeeper获取最新的offset
auto.commit.enable=true
#自动提交的时间间隔
auto.commit.interval.ms=3000
serializer.class=kafka.serializer.StringEncoder
#用于消费的最大数量的消息块缓冲大小，每个块可以等同于fetch.message.max.bytes中数值
queued.max.message.chunks=10
#当有新的consumer加入到group时,将尝试reblance,将partitions的消费端迁移到新的consumer中, 该设置是尝试的次数
rebalance.max.retries=4
# 每次reblance的时间间隔
rebalance.backoff.ms=2000
# 每次重新选举leader的时间
refresh.leader.backoff.ms=600000
# server发送到消费端的最小数据，若是不满足这个数值则会等待直到满足指定大小。默认为1表示立即接收。
fetch.min.bytes=1
# 若是不满足fetch.min.bytes时，等待消费端请求的最长等待时间
fetch.wait.max.ms=100
# 消费者开关
consumer.on-off=true